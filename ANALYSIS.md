# train_1007 vs train_1107 mAP差异分析

## 现象
使用train_1107.py（精确IoU）训练后的mAP50 **低于** train_1007_attmoe_v8l.py（AABB近似）的结果。

## 根本原因

### 1. AABB方法的IoU虚高（主要原因）
- **AABB包围盒更大**：旋转框转为轴对齐矩形时，会包含额外空白区域
- **交集面积虚增**：两个大矩形的交集 > 两个小旋转框的交集
- **IoU被高估**：典型虚高15-50%，取决于旋转角度
- **结果**：很多实际IoU < 0.5的预测被错误地算作True Positive

### 2. 置信度阈值差异（放大效应）
| 参数 | train_1007 | train_1107 | 影响 |
|------|-----------|-----------|------|
| conf_thr | 0.001 | 0.1 | 100倍差异！|
| 保留框数 | ~5000个/图 | ~300个/图 | 显著减少 |
| 召回率 | 接近100% | 75-85% | 受限 |

### 3. 组合效应导致指标虚高
```
train_1007: 低阈值 + 虚高IoU → 大量虚假TP → mAP虚高
train_1107: 高阈值 + 精确IoU → 真实但更低的mAP
```

## 哪个结果更可信？

### ✅ train_1107.py的结果更真实
- 精确计算旋转框IoU（SAT + 精确交集多边形）
- 合理的置信度阈值（0.1）
- **反映模型真实性能**

### ⚠️ train_1007_attmoe_v8l.py的结果虚高
- AABB近似导致IoU高估15-50%
- 极低置信度阈值（0.001）不合理
- **夸大了模型性能**

## 建议的验证实验

### 实验1: 统一置信度阈值
```bash
# 两个模型都用conf_thr=0.1评估
python eval_with_conf_0.1.py --model model_1007.pt --conf 0.1
python eval_with_conf_0.1.py --model model_1107.pt --conf 0.1
```

### 实验2: 统一IoU计算方法
```bash
# 都用精确IoU评估
python eval_with_exact_iou.py --model model_1007.pt
python eval_with_exact_iou.py --model model_1107.pt

# 都用AABB评估（看虚高程度）
python eval_with_aabb_iou.py --model model_1107.pt
```

### 实验3: 可视化对比
对比两个模型在相同测试图上的检测结果：
- 检测框数量
- 高置信度框占比
- 与GT的重叠质量

## 实际应用建议

### 如果追求真实性能评估
→ 使用 **train_1107.py**
- 精确IoU计算
- 合理conf_thr=0.1
- 结果可信，可用于论文发表

### 如果需要快速验证
→ 可用 train_1007_attmoe_v8l.py，但需注意：
- **必须修改conf_thr为0.1**
- 理解mAP可能虚高15-30%
- 用于相对比较而非绝对性能

## 数值示例

假设某模型真实mAP50=0.60：

| 评估方法 | IoU计算 | conf_thr | 测得mAP50 | 偏差 |
|---------|---------|----------|-----------|------|
| **精确（train_1107）** | 旋转框 | 0.1 | 0.60 | 基准 |
| **虚高（train_1007）** | AABB | 0.001 | 0.75-0.85 | +25-40% |
| train_1007修正 | AABB | 0.1 | 0.65-0.70 | +8-15% |

## 结论

**train_1107.py的mAP虽然更低，但更准确、更可信。**

train_1007的高mAP是由于：
1. AABB方法的IoU虚高（技术缺陷）
2. 不合理的极低置信度阈值（参数不当）
3. 两者叠加产生的虚假繁荣

在实际部署和论文发表时，应该：
- ✅ 使用精确的旋转框IoU
- ✅ 使用合理的置信度阈值（0.1-0.3）
- ✅ 报告真实的性能指标
- ❌ 不要被虚高的AABB+低阈值结果误导
